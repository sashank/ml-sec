{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up NLTK data...\n",
      "‚úÖ LSH spam fighting setup completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "print(\"Setting up NLTK data...\")\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "# Initialize text processing tools\n",
    "punctuations = list(string.punctuation)\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "print(\"‚úÖ LSH spam fighting setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH-Based Spam Fighting with Kaggle Ling-Spam Dataset\n",
    "\n",
    "**About LSH (Locality Sensitive Hashing):**\n",
    "- LSH is used to find similar documents efficiently\n",
    "- We'll use MinHash LSH to detect spam emails similar to known spam\n",
    "- The approach: Build an LSH index of known spam emails, then check if new emails are similar\n",
    "\n",
    "**Dataset Setup:**\n",
    "1. Download the Ling-Spam dataset from Kaggle\n",
    "2. Place the CSV file in the 'datasets/' directory \n",
    "3. The CSV should have 'email_text' and 'label' columns\n",
    "4. If no dataset is found, a sample dataset will be created for demonstration\n",
    "\n",
    "**LSH Strategy:**\n",
    "- Extract features (stemmed words) from spam emails during training\n",
    "- Create MinHash signatures for each spam email\n",
    "- Build an LSH index to quickly find similar emails\n",
    "- For new emails: if LSH finds similar spam ‚Üí classify as spam, else ‚Üí ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dataset path: datasets/lingspam_dataset.csv\n",
      "üîÑ Training ratio: 0.7\n",
      "üéØ LSH threshold: 0.5\n",
      "üî¢ MinHash permutations: 128\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Ling-Spam Dataset\n",
    "DATASET_PATH = 'datasets/lingspam_dataset.csv'\n",
    "TRAINING_SET_RATIO = 0.7\n",
    "\n",
    "# LSH parameters\n",
    "LSH_THRESHOLD = 0.5  # Jaccard similarity threshold\n",
    "NUM_PERM = 128      # Number of MinHash permutations\n",
    "\n",
    "print(f\"üìÅ Dataset path: {DATASET_PATH}\")\n",
    "print(f\"üîÑ Training ratio: {TRAINING_SET_RATIO}\")\n",
    "print(f\"üéØ LSH threshold: {LSH_THRESHOLD}\")\n",
    "print(f\"üî¢ MinHash permutations: {NUM_PERM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Sample preprocessing: 'This is a test email for LSH processing!' ‚Üí ['test', 'email', 'lsh', 'process']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Process email text into stemmed tokens for LSH analysis\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw email text\n",
    "        \n",
    "    Returns:\n",
    "        list: List of stemmed tokens\n",
    "    \"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return []\n",
    "    \n",
    "    # Convert to lowercase and tokenize\n",
    "    tokens = nltk.word_tokenize(str(text).lower())\n",
    "    \n",
    "    # Remove punctuation and filter tokens\n",
    "    tokens = [token.strip(\"\".join(punctuations)) for token in tokens \n",
    "              if token not in punctuations and len(token) > 1]\n",
    "    \n",
    "    # Remove stopwords and stem tokens\n",
    "    if len(tokens) > 2:\n",
    "        return [stemmer.stem(word) for word in tokens \n",
    "                if word not in stopwords_set and word.isalpha()]\n",
    "    return []\n",
    "\n",
    "# Test preprocessing\n",
    "test_text = \"This is a test email for LSH processing!\"\n",
    "test_tokens = preprocess_text(test_text)\n",
    "print(f\"üß™ Sample preprocessing: '{test_text}' ‚Üí {test_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Dataset not found at datasets/lingspam_dataset.csv\n",
      "Creating sample dataset for LSH demonstration...\n",
      "Created sample dataset with 16 emails\n",
      "\n",
      "üìä Dataset summary:\n",
      "Total emails: 16\n",
      "Label distribution:\n",
      "label\n",
      "ham     8\n",
      "spam    8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_lingspam_dataset():\n",
    "    \"\"\"\n",
    "    Load the Ling-Spam dataset from CSV format\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataset with email_text and label columns\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(DATASET_PATH):\n",
    "            df = pd.read_csv(DATASET_PATH)\n",
    "            print(f\"‚úÖ Loaded dataset from {DATASET_PATH}\")\n",
    "            print(f\"Dataset shape: {df.shape}\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Dataset not found at {DATASET_PATH}\")\n",
    "            print(\"Creating sample dataset for LSH demonstration...\")\n",
    "            \n",
    "            # Create sample dataset for LSH demonstration\n",
    "            sample_data = {\n",
    "                'email_text': [\n",
    "                    \"Dear colleague, I hope this email finds you well. We are organizing a linguistics conference next month.\",\n",
    "                    \"URGENT!!! You have won $1,000,000!!! Click here now to claim your prize!!! Limited time offer!!!\",\n",
    "                    \"The latest research on phonetics shows interesting patterns in vowel recognition systems.\",\n",
    "                    \"FREE VIAGRA!!! Buy now with 90% discount!!! No prescription needed!!! Order today!!!\",\n",
    "                    \"Thank you for your submission to the journal. We will review it and get back to you soon.\",\n",
    "                    \"MAKE MONEY FAST!!! Work from home!!! Earn $5000 per week!!! No experience required!!!\",\n",
    "                    \"The syntax paper you requested is attached. Please let me know if you need any clarifications.\",\n",
    "                    \"CREDIT CARD DEBT FORGIVENESS!!! Eliminate your debt today!!! Government program!!!\",\n",
    "                    \"Could you please review the manuscript on morphological analysis? Your expertise would be valuable.\",\n",
    "                    \"WIN A FREE IPHONE!!! Click now!!! Limited time offer!!! Act fast!!!\",\n",
    "                    \"The linguistics department is hosting a seminar on computational linguistics next Friday.\",\n",
    "                    \"HOT SINGLES IN YOUR AREA!!! Meet them tonight!!! No strings attached!!!\",\n",
    "                    \"I found your paper on semantic analysis very insightful. Would you be interested in collaboration?\",\n",
    "                    \"LOSE 30 POUNDS IN 30 DAYS!!! Revolutionary diet pill!!! Doctor approved!!!\",\n",
    "                    \"The conference proceedings are now available online. Thank you for your participation.\",\n",
    "                    \"WORK FROM HOME!!! Earn $3000/week!!! No experience needed!!! Start today!!!\"\n",
    "                ],\n",
    "                'label': ['ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', \n",
    "                         'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam']\n",
    "            }\n",
    "            \n",
    "            df = pd.DataFrame(sample_data)\n",
    "            print(f\"Created sample dataset with {len(df)} emails\")\n",
    "            return df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_lingspam_dataset()\n",
    "if dataset is not None:\n",
    "    print(f\"\\nüìä Dataset summary:\")\n",
    "    print(f\"Total emails: {len(dataset)}\")\n",
    "    print(f\"Label distribution:\")\n",
    "    print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Dataset split for LSH:\n",
      "Training set: 11 emails\n",
      "Testing set: 5 emails\n",
      "Training spam/ham ratio: 5/6\n",
      "Testing spam/ham ratio: 3/2\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for LSH processing\n",
    "# Convert labels to binary format (1 for ham, 0 for spam)\n",
    "dataset['label_binary'] = dataset['label'].map({'ham': 1, 'spam': 0})\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = dataset['email_text']\n",
    "y = dataset['label_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=(1 - TRAINING_SET_RATIO), \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìù Dataset split for LSH:\")\n",
    "print(f\"Training set: {len(X_train)} emails\")\n",
    "print(f\"Testing set: {len(X_test)} emails\")\n",
    "print(f\"Training spam/ham ratio: {sum(y_train == 0)}/{sum(y_train == 1)}\")\n",
    "print(f\"Testing spam/ham ratio: {sum(y_test == 0)}/{sum(y_test == 1)}\")\n",
    "\n",
    "# Create lists for easier processing\n",
    "train_data = list(zip(X_train, y_train))\n",
    "test_data = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Training data for LSH:\n",
      "Spam emails for LSH index: 5\n",
      "Ham emails (reference): 6\n",
      "Total training emails: 11\n",
      "\n",
      "üìß Sample spam email (first 100 chars):\n",
      "'WORK FROM HOME!!! Earn $3000/week!!! No experience needed!!! Start today!!!...'\n"
     ]
    }
   ],
   "source": [
    "# Extract only spam emails from training set for LSH index\n",
    "spam_emails = [(email_text, label) for email_text, label in train_data if label == 0]\n",
    "ham_emails = [(email_text, label) for email_text, label in train_data if label == 1]\n",
    "\n",
    "print(f\"üéØ Training data for LSH:\")\n",
    "print(f\"Spam emails for LSH index: {len(spam_emails)}\")\n",
    "print(f\"Ham emails (reference): {len(ham_emails)}\")\n",
    "print(f\"Total training emails: {len(train_data)}\")\n",
    "\n",
    "# Show sample spam email for LSH\n",
    "if spam_emails:\n",
    "    print(f\"\\nüìß Sample spam email (first 100 chars):\")\n",
    "    print(f\"'{spam_emails[0][0][:100]}...'\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No spam emails found in training set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è  Initializing LSH with threshold=0.5, num_perm=128\n",
      "‚úÖ LSH matcher initialized successfully!\n",
      "üìä LSH Configuration:\n",
      "  ‚Ä¢ Jaccard similarity threshold: 0.5\n",
      "  ‚Ä¢ MinHash permutations: 128\n",
      "  ‚Ä¢ Ready to index spam emails...\n"
     ]
    }
   ],
   "source": [
    "# Initialize MinHashLSH matcher\n",
    "print(f\"üèóÔ∏è  Initializing LSH with threshold={LSH_THRESHOLD}, num_perm={NUM_PERM}\")\n",
    "lsh = MinHashLSH(threshold=LSH_THRESHOLD, num_perm=NUM_PERM)\n",
    "\n",
    "print(f\"‚úÖ LSH matcher initialized successfully!\")\n",
    "print(f\"üìä LSH Configuration:\")\n",
    "print(f\"  ‚Ä¢ Jaccard similarity threshold: {LSH_THRESHOLD}\")\n",
    "print(f\"  ‚Ä¢ MinHash permutations: {NUM_PERM}\")\n",
    "print(f\"  ‚Ä¢ Ready to index spam emails...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Building LSH index with spam emails...\n",
      "  Indexed 1 spam emails...\n",
      "‚úÖ LSH index built successfully!\n",
      "üìä Index summary:\n",
      "  ‚Ä¢ Total spam emails processed: 5\n",
      "  ‚Ä¢ Successfully indexed: 5\n",
      "  ‚Ä¢ Skipped (too few tokens): 0\n",
      "  ‚Ä¢ LSH index ready for similarity queries!\n"
     ]
    }
   ],
   "source": [
    "# Build LSH index with spam emails from training set\n",
    "print(\"üîç Building LSH index with spam emails...\")\n",
    "\n",
    "indexed_count = 0\n",
    "for idx, (email_text, label) in enumerate(spam_emails):\n",
    "    # Create MinHash for this spam email\n",
    "    minhash = MinHash(num_perm=NUM_PERM)\n",
    "    \n",
    "    # Process email text to get stemmed tokens\n",
    "    stems = preprocess_text(email_text)\n",
    "    \n",
    "    # Skip emails with too few tokens\n",
    "    if len(stems) < 2:\n",
    "        print(f\"‚ö†Ô∏è  Skipping email {idx}: too few tokens ({len(stems)})\")\n",
    "        continue\n",
    "    \n",
    "    # Add tokens to MinHash\n",
    "    for stem in stems:\n",
    "        minhash.update(stem.encode('utf-8'))\n",
    "    \n",
    "    # Insert into LSH index with unique identifier\n",
    "    email_id = f\"spam_email_{idx}\"\n",
    "    lsh.insert(email_id, minhash)\n",
    "    indexed_count += 1\n",
    "    \n",
    "    if idx % 5 == 0:  # Progress indicator\n",
    "        print(f\"  Indexed {indexed_count} spam emails...\")\n",
    "\n",
    "print(f\"‚úÖ LSH index built successfully!\")\n",
    "print(f\"üìä Index summary:\")\n",
    "print(f\"  ‚Ä¢ Total spam emails processed: {len(spam_emails)}\")\n",
    "print(f\"  ‚Ä¢ Successfully indexed: {indexed_count}\")\n",
    "print(f\"  ‚Ä¢ Skipped (too few tokens): {len(spam_emails) - indexed_count}\")\n",
    "print(f\"  ‚Ä¢ LSH index ready for similarity queries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ LSH prediction test:\n",
      "  Email (first 80 chars): 'CREDIT CARD DEBT FORGIVENESS!!! Eliminate your debt today!!! Government program!...'\n",
      "  Actual label: spam\n",
      "  LSH prediction: ham\n",
      "  Match: ‚ùå\n"
     ]
    }
   ],
   "source": [
    "def lsh_predict_label(email_text):\n",
    "    \"\"\"\n",
    "    Predict email label using LSH similarity matching\n",
    "    \n",
    "    Args:\n",
    "        email_text (str): Email text content\n",
    "        \n",
    "    Returns:\n",
    "        int: 0 if predicted spam, 1 if predicted ham, -1 if error\n",
    "    \"\"\"\n",
    "    # Preprocess email text\n",
    "    stems = preprocess_text(email_text)\n",
    "    \n",
    "    # Check if we have enough tokens\n",
    "    if len(stems) < 2:\n",
    "        return -1  # Error: insufficient tokens\n",
    "    \n",
    "    # Create MinHash for the email\n",
    "    minhash = MinHash(num_perm=NUM_PERM)\n",
    "    for stem in stems:\n",
    "        minhash.update(stem.encode('utf-8'))\n",
    "    \n",
    "    # Query LSH index for similar spam emails\n",
    "    matches = lsh.query(minhash)\n",
    "    \n",
    "    # If we find matches with known spam emails, classify as spam\n",
    "    if matches:\n",
    "        return 0  # Spam\n",
    "    else:\n",
    "        return 1  # Ham\n",
    "\n",
    "# Test the prediction function\n",
    "if len(test_data) > 0:\n",
    "    test_email, test_label = test_data[0]\n",
    "    predicted = lsh_predict_label(test_email)\n",
    "    actual = \"spam\" if test_label == 0 else \"ham\"\n",
    "    predicted_str = \"spam\" if predicted == 0 else \"ham\" if predicted == 1 else \"error\"\n",
    "    \n",
    "    print(f\"üß™ LSH prediction test:\")\n",
    "    print(f\"  Email (first 80 chars): '{test_email[:80]}...'\")\n",
    "    print(f\"  Actual label: {actual}\")\n",
    "    print(f\"  LSH prediction: {predicted_str}\")\n",
    "    print(f\"  Match: {'‚úÖ' if (test_label == predicted) else '‚ùå'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No test data available for prediction test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing LSH classifier on test set...\n",
      "üìä LSH Classification Results:\n",
      "True Positives (Spam ‚Üí Spam): 0\n",
      "True Negatives (Ham ‚Üí Ham): 2\n",
      "False Positives (Ham ‚Üí Spam): 0\n",
      "False Negatives (Spam ‚Üí Ham): 3\n",
      "Parsing errors (skipped): 0\n",
      "Total processed: 5\n",
      "Total predictions: 5\n",
      "üéØ Preliminary accuracy: 40.0%\n"
     ]
    }
   ],
   "source": [
    "# Test LSH classifier on the test set\n",
    "print(\"üß™ Testing LSH classifier on test set...\")\n",
    "\n",
    "# Initialize confusion matrix variables\n",
    "fp = 0  # False Positive: Ham classified as Spam\n",
    "tp = 0  # True Positive: Spam classified as Spam  \n",
    "fn = 0  # False Negative: Spam classified as Ham\n",
    "tn = 0  # True Negative: Ham classified as Ham\n",
    "\n",
    "skipped = 0  # Count of emails with parsing errors\n",
    "\n",
    "# Classify each email in the test set\n",
    "for idx, (email_text, true_label) in enumerate(test_data):\n",
    "    # Get LSH prediction\n",
    "    predicted_label = lsh_predict_label(email_text)\n",
    "    \n",
    "    # Skip emails with parsing errors\n",
    "    if predicted_label == -1:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    if predicted_label == 0:  # Predicted spam\n",
    "        if true_label == 1:  # Actually ham\n",
    "            fp += 1\n",
    "        else:  # Actually spam\n",
    "            tp += 1\n",
    "    else:  # Predicted ham\n",
    "        if true_label == 1:  # Actually ham\n",
    "            tn += 1\n",
    "        else:  # Actually spam\n",
    "            fn += 1\n",
    "\n",
    "# Calculate totals\n",
    "total_predictions = tp + tn + fp + fn\n",
    "total_processed = len(test_data)\n",
    "\n",
    "print(f\"üìä LSH Classification Results:\")\n",
    "print(f\"True Positives (Spam ‚Üí Spam): {tp}\")\n",
    "print(f\"True Negatives (Ham ‚Üí Ham): {tn}\")\n",
    "print(f\"False Positives (Ham ‚Üí Spam): {fp}\")\n",
    "print(f\"False Negatives (Spam ‚Üí Ham): {fn}\")\n",
    "print(f\"Parsing errors (skipped): {skipped}\")\n",
    "print(f\"Total processed: {total_processed}\")\n",
    "print(f\"Total predictions: {total_predictions}\")\n",
    "\n",
    "if total_predictions > 0:\n",
    "    accuracy = (tp + tn) / total_predictions\n",
    "    print(f\"üéØ Preliminary accuracy: {accuracy:.1%}\")\n",
    "else:\n",
    "    print(\"‚ùå No valid predictions made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Confusion Matrix (Raw Counts):\n",
      "Predicted ‚Üí\n",
      "Actual ‚Üì     Ham    Spam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1' style='border-collapse: collapse;'><tr><th></th><th>Predicted Ham</th><th>Predicted Spam</th></tr><tr><td><b>Actual Ham</b></td><td>2</td><td>0</td></tr><tr><td><b>Actual Spam</b></td><td>3</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Interpretation:\n",
      "‚Ä¢ True Negatives (TN): 2 - Ham emails correctly identified as Ham\n",
      "‚Ä¢ False Positives (FP): 0 - Ham emails incorrectly identified as Spam\n",
      "‚Ä¢ False Negatives (FN): 3 - Spam emails incorrectly identified as Ham\n",
      "‚Ä¢ True Positives (TP): 0 - Spam emails correctly identified as Spam\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "if total_predictions > 0:\n",
    "    print(\"üìà Confusion Matrix (Raw Counts):\")\n",
    "    print(\"Predicted ‚Üí\")\n",
    "    print(\"Actual ‚Üì     Ham    Spam\")\n",
    "    \n",
    "    # Create HTML table for better visualization\n",
    "    html_table = \"<table border='1' style='border-collapse: collapse;'>\"\n",
    "    html_table += \"<tr><th></th><th>Predicted Ham</th><th>Predicted Spam</th></tr>\"\n",
    "    html_table += f\"<tr><td><b>Actual Ham</b></td><td>{tn}</td><td>{fp}</td></tr>\"\n",
    "    html_table += f\"<tr><td><b>Actual Spam</b></td><td>{fn}</td><td>{tp}</td></tr>\"\n",
    "    html_table += \"</table>\"\n",
    "    \n",
    "    display(HTML(html_table))\n",
    "    \n",
    "    print(f\"\\nüéØ Interpretation:\")\n",
    "    print(f\"‚Ä¢ True Negatives (TN): {tn} - Ham emails correctly identified as Ham\")\n",
    "    print(f\"‚Ä¢ False Positives (FP): {fp} - Ham emails incorrectly identified as Spam\")\n",
    "    print(f\"‚Ä¢ False Negatives (FN): {fn} - Spam emails incorrectly identified as Ham\")\n",
    "    print(f\"‚Ä¢ True Positives (TP): {tp} - Spam emails correctly identified as Spam\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot display confusion matrix - no valid predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Performance Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1' style='border-collapse: collapse;'><tr><th></th><th>Predicted Ham</th><th>Predicted Spam</th></tr><tr><td><b>Actual Ham</b></td><td>40.0%</td><td>0.0%</td></tr><tr><td><b>Actual Spam</b></td><td>60.0%</td><td>0.0%</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà LSH Classifier Performance:\n",
      "‚Ä¢ Accuracy: 40.0% - Overall correct predictions\n",
      "‚Ä¢ Precision: 0.0% - Of predicted spam, how much was actually spam\n",
      "‚Ä¢ Recall: 0.0% - Of actual spam, how much was detected\n",
      "‚Ä¢ F1-Score: 0.000 - Harmonic mean of precision and recall\n",
      "\n",
      "üîç LSH-Specific Insights:\n",
      "‚Ä¢ Similarity threshold: 0.5\n",
      "‚Ä¢ MinHash permutations: 128\n",
      "‚Ä¢ Spam emails in index: 5\n",
      "‚Ä¢ Processing errors: 0 emails\n"
     ]
    }
   ],
   "source": [
    "# Display performance metrics\n",
    "if total_predictions > 0:\n",
    "    print(\"üìä Performance Metrics:\")\n",
    "    \n",
    "    # Calculate percentages\n",
    "    tn_pct = f\"{tn/total_predictions:.1%}\"\n",
    "    fp_pct = f\"{fp/total_predictions:.1%}\"\n",
    "    fn_pct = f\"{fn/total_predictions:.1%}\"\n",
    "    tp_pct = f\"{tp/total_predictions:.1%}\"\n",
    "    \n",
    "    # Create HTML table for percentages\n",
    "    html_table_pct = \"<table border='1' style='border-collapse: collapse;'>\"\n",
    "    html_table_pct += \"<tr><th></th><th>Predicted Ham</th><th>Predicted Spam</th></tr>\"\n",
    "    html_table_pct += f\"<tr><td><b>Actual Ham</b></td><td>{tn_pct}</td><td>{fp_pct}</td></tr>\"\n",
    "    html_table_pct += f\"<tr><td><b>Actual Spam</b></td><td>{fn_pct}</td><td>{tp_pct}</td></tr>\"\n",
    "    html_table_pct += \"</table>\"\n",
    "    \n",
    "    display(HTML(html_table_pct))\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    accuracy = (tp + tn) / total_predictions\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìà LSH Classifier Performance:\")\n",
    "    print(f\"‚Ä¢ Accuracy: {accuracy:.1%} - Overall correct predictions\")\n",
    "    print(f\"‚Ä¢ Precision: {precision:.1%} - Of predicted spam, how much was actually spam\")\n",
    "    print(f\"‚Ä¢ Recall: {recall:.1%} - Of actual spam, how much was detected\")\n",
    "    print(f\"‚Ä¢ F1-Score: {f1_score:.3f} - Harmonic mean of precision and recall\")\n",
    "    \n",
    "    # LSH-specific insights\n",
    "    print(f\"\\nüîç LSH-Specific Insights:\")\n",
    "    print(f\"‚Ä¢ Similarity threshold: {LSH_THRESHOLD}\")\n",
    "    print(f\"‚Ä¢ MinHash permutations: {NUM_PERM}\")\n",
    "    print(f\"‚Ä¢ Spam emails in index: {indexed_count}\")\n",
    "    print(f\"‚Ä¢ Processing errors: {skipped} emails\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot calculate performance metrics - no valid predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ LSH-Based Spam Fighting - Ling-Spam Dataset Analysis Complete!\n",
      "===========================================================================\n",
      "üéØ Final LSH Classification Accuracy: 40.0%\n",
      "\n",
      "üí° Key Results:\n",
      "‚Ä¢ Dataset size: 16 emails\n",
      "‚Ä¢ Training set: 11 emails\n",
      "‚Ä¢ Test set: 5 emails\n",
      "‚Ä¢ LSH index size: 5 spam signatures\n",
      "‚Ä¢ Similarity threshold: 0.5\n",
      "‚Ä¢ Method: MinHash LSH with Jaccard similarity\n",
      "‚ùå Poor performance. LSH may not be suitable for this dataset or needs adjustment.\n",
      "\n",
      "üîß LSH Tuning Recommendations:\n",
      "‚Ä¢ Low precision ‚Üí Increase similarity threshold (current: 0.5)\n",
      "‚Ä¢ Low recall ‚Üí Decrease similarity threshold or add more spam examples\n",
      "‚Ä¢ Try different num_perm values (current: 128)\n",
      "‚Ä¢ Improve text preprocessing (stemming, n-grams)\n",
      "‚Ä¢ Consider ensemble with other methods\n",
      "\n",
      "üöÄ Next Steps:\n",
      "‚Ä¢ Experiment with different LSH thresholds (0.3, 0.7)\n",
      "‚Ä¢ Try different MinHash permutation counts (64, 256)\n",
      "‚Ä¢ Combine LSH with other features (email headers, length)\n",
      "‚Ä¢ Use LSH for initial filtering, then apply ML classifiers\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final summary and LSH analysis\n",
    "print(\"üéâ LSH-Based Spam Fighting - Ling-Spam Dataset Analysis Complete!\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "if total_predictions > 0:\n",
    "    accuracy = (tp + tn) / total_predictions\n",
    "    print(f\"üéØ Final LSH Classification Accuracy: {accuracy:.1%}\")\n",
    "    \n",
    "    print(f\"\\nüí° Key Results:\")\n",
    "    print(f\"‚Ä¢ Dataset size: {len(dataset)} emails\")\n",
    "    print(f\"‚Ä¢ Training set: {len(train_data)} emails\")\n",
    "    print(f\"‚Ä¢ Test set: {len(test_data)} emails\")\n",
    "    print(f\"‚Ä¢ LSH index size: {indexed_count} spam signatures\")\n",
    "    print(f\"‚Ä¢ Similarity threshold: {LSH_THRESHOLD}\")\n",
    "    print(f\"‚Ä¢ Method: MinHash LSH with Jaccard similarity\")\n",
    "    \n",
    "    # Performance analysis\n",
    "    if accuracy > 0.8:\n",
    "        print(f\"‚úÖ Excellent performance! LSH effectively detects similar spam patterns.\")\n",
    "    elif accuracy > 0.6:\n",
    "        print(f\"‚ö†Ô∏è  Moderate performance. Consider tuning LSH parameters or preprocessing.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Poor performance. LSH may not be suitable for this dataset or needs adjustment.\")\n",
    "    \n",
    "    # LSH-specific recommendations\n",
    "    print(f\"\\nüîß LSH Tuning Recommendations:\")\n",
    "    if precision < 0.7:\n",
    "        print(f\"‚Ä¢ Low precision ‚Üí Increase similarity threshold (current: {LSH_THRESHOLD})\")\n",
    "    if recall < 0.7:\n",
    "        print(f\"‚Ä¢ Low recall ‚Üí Decrease similarity threshold or add more spam examples\")\n",
    "    if accuracy < 0.7:\n",
    "        print(f\"‚Ä¢ Try different num_perm values (current: {NUM_PERM})\")\n",
    "        print(f\"‚Ä¢ Improve text preprocessing (stemming, n-grams)\")\n",
    "        print(f\"‚Ä¢ Consider ensemble with other methods\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Next Steps:\")\n",
    "    print(f\"‚Ä¢ Experiment with different LSH thresholds (0.3, 0.7)\")\n",
    "    print(f\"‚Ä¢ Try different MinHash permutation counts (64, 256)\")\n",
    "    print(f\"‚Ä¢ Combine LSH with other features (email headers, length)\")\n",
    "    print(f\"‚Ä¢ Use LSH for initial filtering, then apply ML classifiers\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå LSH classification failed - check dataset and preprocessing\")\n",
    "\n",
    "print(\"=\"*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Create Enhanced Sample Dataset for LSH Testing\n",
    "\n",
    "The LSH method works better with more data and similar patterns. Run the cell below to create a larger, more realistic dataset for testing LSH effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° To create an enhanced dataset for better LSH testing, uncomment the line above and run this cell.\n",
      "üìà The enhanced dataset includes similar spam patterns that work well with LSH similarity detection.\n"
     ]
    }
   ],
   "source": [
    "# Create enhanced sample dataset for better LSH demonstration\n",
    "def create_enhanced_lingspam_dataset(filename='datasets/lingspam_dataset.csv', num_emails=50):\n",
    "    \"\"\"\n",
    "    Create a larger sample dataset with patterns that work well with LSH\n",
    "    \"\"\"\n",
    "    # Create datasets directory if it doesn't exist\n",
    "    os.makedirs('datasets', exist_ok=True)\n",
    "    \n",
    "    # Common spam patterns (to create similarity for LSH)\n",
    "    spam_templates = [\n",
    "        \"URGENT!!! You have won ${} dollars!!! Click here now to claim your prize!!! Limited time offer!!!\",\n",
    "        \"FREE {}!!! Buy now with {}% discount!!! No {} needed!!! Order today!!!\",\n",
    "        \"MAKE MONEY FAST!!! Work from home!!! Earn ${}/week!!! No experience required!!!\",\n",
    "        \"CREDIT CARD DEBT FORGIVENESS!!! Eliminate your {} today!!! {} program!!!\",\n",
    "        \"HOT {} IN YOUR AREA!!! Meet them tonight!!! No strings attached!!!\",\n",
    "        \"LOSE {} POUNDS IN {} DAYS!!! Revolutionary {}!!! Doctor approved!!!\",\n",
    "        \"WIN A FREE {}!!! Click now!!! Limited time offer!!! Act fast!!!\",\n",
    "        \"WORK FROM HOME!!! Earn ${}/week!!! No {} needed!!! Start today!!!\",\n",
    "        \"FREE MONEY!!! {} grants available!!! Claim yours now!!! No repayment!!!\",\n",
    "        \"MIRACLE CURE!!! {} without {} or {}!!! 100% guaranteed!!!\"\n",
    "    ]\n",
    "    \n",
    "    # Spam variations\n",
    "    amounts = [\"1000000\", \"500000\", \"250000\", \"100000\"]\n",
    "    products = [\"VIAGRA\", \"CIALIS\", \"PILLS\", \"MEDICINE\"]\n",
    "    percentages = [\"90\", \"80\", \"70\", \"95\"]\n",
    "    requirements = [\"prescription\", \"experience\", \"payment\", \"commitment\"]\n",
    "    periods = [\"30\", \"14\", \"7\", \"60\"]\n",
    "    items = [\"IPHONE\", \"LAPTOP\", \"CAR\", \"VACATION\"]\n",
    "    people = [\"SINGLES\", \"FRIENDS\", \"PARTNERS\", \"DATES\"]\n",
    "    benefits = [\"Government\", \"Federal\", \"State\", \"Private\"]\n",
    "    activities = [\"diet\", \"exercise\", \"work\", \"effort\"]\n",
    "    \n",
    "    # Ham email templates (academic/professional)\n",
    "    ham_templates = [\n",
    "        \"Dear colleague, I hope this email finds you well. We are organizing a {} conference next month on {}.\",\n",
    "        \"The latest research on {} shows interesting patterns in {} systems and methodologies.\",\n",
    "        \"Thank you for your submission to the {}. We will review it and get back to you within {} days.\",\n",
    "        \"The {} paper you requested is attached. Please let me know if you need any clarifications on {}.\",\n",
    "        \"Could you please review the manuscript on {}? Your expertise in {} would be valuable.\",\n",
    "        \"The {} department is hosting a seminar on {} next Friday at {} in room {}.\",\n",
    "        \"I found your paper on {} very insightful. Would you be interested in collaboration on {}?\",\n",
    "        \"The conference proceedings for {} are now available online. Thank you for your participation in {}.\",\n",
    "        \"Please find attached the corrected version of the {} algorithm for {} classification.\",\n",
    "        \"The workshop on {} has been scheduled for next month. We would appreciate your input on {}.\"\n",
    "    ]\n",
    "    \n",
    "    # Ham variations\n",
    "    conferences = [\"linguistics\", \"computer science\", \"AI\", \"NLP\"]\n",
    "    topics = [\"phonetics\", \"syntax\", \"semantics\", \"morphology\"]\n",
    "    journals = [\"journal\", \"conference\", \"symposium\", \"workshop\"]\n",
    "    days = [\"5-7\", \"10-14\", \"2-3\", \"7-10\"]\n",
    "    papers = [\"syntax\", \"phoneme\", \"semantic\", \"morphological\"]\n",
    "    subjects = [\"machine learning\", \"natural language\", \"computational linguistics\", \"AI\"]\n",
    "    departments = [\"linguistics\", \"computer science\", \"AI research\", \"NLP\"]\n",
    "    times = [\"10 AM\", \"2 PM\", \"9 AM\", \"3 PM\"]\n",
    "    rooms = [\"A101\", \"B205\", \"C301\", \"D150\"]\n",
    "    algorithms = [\"classification\", \"clustering\", \"prediction\", \"analysis\"]\n",
    "    \n",
    "    emails = []\n",
    "    labels = []\n",
    "    \n",
    "    # Generate varied spam emails\n",
    "    for i in range(num_emails // 2):\n",
    "        template = spam_templates[i % len(spam_templates)]\n",
    "        \n",
    "        # Fill template with variations\n",
    "        if \"{}\" in template:\n",
    "            if \"won\" in template:\n",
    "                spam_email = template.format(amounts[i % len(amounts)])\n",
    "            elif \"FREE\" in template and \"discount\" in template:\n",
    "                spam_email = template.format(\n",
    "                    products[i % len(products)], \n",
    "                    percentages[i % len(percentages)], \n",
    "                    requirements[i % len(requirements)]\n",
    "                )\n",
    "            elif \"EARN\" in template:\n",
    "                spam_email = template.format(amounts[i % len(amounts)][:4])\n",
    "            elif \"DEBT\" in template:\n",
    "                spam_email = template.format(\"debt\", benefits[i % len(benefits)])\n",
    "            elif \"HOT\" in template:\n",
    "                spam_email = template.format(people[i % len(people)])\n",
    "            elif \"LOSE\" in template:\n",
    "                spam_email = template.format(\n",
    "                    periods[i % len(periods)], \n",
    "                    periods[i % len(periods)], \n",
    "                    \"diet pill\"\n",
    "                )\n",
    "            elif \"WIN\" in template:\n",
    "                spam_email = template.format(items[i % len(items)])\n",
    "            elif \"WORK\" in template:\n",
    "                spam_email = template.format(amounts[i % len(amounts)][:4], requirements[i % len(requirements)])\n",
    "            elif \"grants\" in template:\n",
    "                spam_email = template.format(benefits[i % len(benefits)])\n",
    "            elif \"MIRACLE\" in template:\n",
    "                spam_email = template.format(\"lose weight\", activities[i % len(activities)], activities[(i+1) % len(activities)])\n",
    "            else:\n",
    "                spam_email = template\n",
    "        else:\n",
    "            spam_email = template\n",
    "            \n",
    "        # Add some variation\n",
    "        if i > 0:\n",
    "            spam_email += f\" Reference: SPAM{i:03d}. ID: {i+1000}.\"\n",
    "            \n",
    "        emails.append(spam_email)\n",
    "        labels.append('spam')\n",
    "        \n",
    "        # Generate varied ham emails\n",
    "        ham_template = ham_templates[i % len(ham_templates)]\n",
    "        if \"{}\" in ham_template:\n",
    "            if \"conference\" in ham_template:\n",
    "                ham_email = ham_template.format(conferences[i % len(conferences)], topics[i % len(topics)])\n",
    "            elif \"research\" in ham_template:\n",
    "                ham_email = ham_template.format(topics[i % len(topics)], subjects[i % len(subjects)])\n",
    "            elif \"submission\" in ham_template:\n",
    "                ham_email = ham_template.format(journals[i % len(journals)], days[i % len(days)])\n",
    "            elif \"paper\" in ham_template:\n",
    "                ham_email = ham_template.format(papers[i % len(papers)], topics[i % len(topics)])\n",
    "            elif \"manuscript\" in ham_template:\n",
    "                ham_email = ham_template.format(subjects[i % len(subjects)], topics[i % len(topics)])\n",
    "            elif \"department\" in ham_template:\n",
    "                ham_email = ham_template.format(\n",
    "                    departments[i % len(departments)], \n",
    "                    subjects[i % len(subjects)], \n",
    "                    times[i % len(times)], \n",
    "                    rooms[i % len(rooms)]\n",
    "                )\n",
    "            elif \"insightful\" in ham_template:\n",
    "                ham_email = ham_template.format(topics[i % len(topics)], subjects[i % len(subjects)])\n",
    "            elif \"proceedings\" in ham_template:\n",
    "                ham_email = ham_template.format(conferences[i % len(conferences)], topics[i % len(topics)])\n",
    "            elif \"algorithm\" in ham_template:\n",
    "                ham_email = ham_template.format(algorithms[i % len(algorithms)], subjects[i % len(subjects)])\n",
    "            elif \"workshop\" in ham_template:\n",
    "                ham_email = ham_template.format(subjects[i % len(subjects)], topics[i % len(topics)])\n",
    "            else:\n",
    "                ham_email = ham_template\n",
    "        else:\n",
    "            ham_email = ham_template\n",
    "            \n",
    "        # Add variation\n",
    "        if i > 0:\n",
    "            ham_email += f\" Email ref: HAM{i:03d}. Best regards, Academic Team.\"\n",
    "            \n",
    "        emails.append(ham_email)\n",
    "        labels.append('ham')\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'email_text': emails,\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"‚úÖ Enhanced dataset created: {filename}\")\n",
    "    print(f\"üìä Contains {len(df)} emails ({len(df[df['label']=='spam'])} spam, {len(df[df['label']=='ham'])} ham)\")\n",
    "    print(f\"üîç Dataset designed for LSH similarity detection\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Uncomment the line below to create an enhanced dataset\n",
    "# enhanced_df = create_enhanced_lingspam_dataset(num_emails=100)\n",
    "\n",
    "print(\"üí° To create an enhanced dataset for better LSH testing, uncomment the line above and run this cell.\")\n",
    "print(\"üìà The enhanced dataset includes similar spam patterns that work well with LSH similarity detection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ LSH Notebook Successfully Converted to Ling-Spam Dataset!\n",
    "\n",
    "### **Key Changes Made:**\n",
    "\n",
    "1. **Dataset Format Conversion**: \n",
    "   - üîÑ **From**: TREC 2007 corpus (email files + labels file)\n",
    "   - üîÑ **To**: Kaggle Ling-Spam dataset (CSV with email_text + label columns)\n",
    "\n",
    "2. **Modern Dependencies**: \n",
    "   - ‚úÖ Updated imports (pandas, sklearn, modern NLTK)\n",
    "   - ‚úÖ Text preprocessing with stemming and stopword removal\n",
    "   - ‚úÖ Proper error handling and progress indicators\n",
    "\n",
    "3. **LSH Implementation**: \n",
    "   - ‚úÖ MinHash LSH with configurable parameters\n",
    "   - ‚úÖ Jaccard similarity-based spam detection\n",
    "   - ‚úÖ Complete evaluation pipeline with confusion matrix\n",
    "\n",
    "### **LSH Method Explanation:**\n",
    "- **Training**: Build LSH index with MinHash signatures of known spam emails\n",
    "- **Prediction**: Check if new email has similar MinHash to indexed spam\n",
    "- **Advantage**: Very fast similarity detection for large datasets\n",
    "- **Challenge**: Requires sufficient similar examples to work effectively\n",
    "\n",
    "### **Performance Notes:**\n",
    "- üìä **Current accuracy**: 40% on small sample dataset\n",
    "- üìâ **Low performance expected** due to small sample size and diverse spam patterns\n",
    "- üìà **Will improve with**: Larger dataset, similar spam patterns, parameter tuning\n",
    "\n",
    "### **To Improve LSH Performance:**\n",
    "1. **Use the enhanced dataset generator** (uncomment and run the last cell)\n",
    "2. **Tune LSH parameters**: Try threshold=0.3 for higher recall\n",
    "3. **Add more training data**: LSH works better with more examples\n",
    "4. **Preprocess improvements**: Use n-grams, better stemming\n",
    "5. **Combine methods**: Use LSH as first filter, then apply ML classifier\n",
    "\n",
    "The notebook demonstrates LSH concepts and provides a foundation for larger-scale spam detection systems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
